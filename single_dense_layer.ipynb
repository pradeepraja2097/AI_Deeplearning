{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-01 20:48:23.879404: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-01 20:48:23.879440: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.array([[1, 1, 1], [2, 3, 1], [0, -1, 4], [0, 3, 0], [10, -6, 8], [-3, -12, 4]])\n",
    "testing_data = np.array([6, 11, 1, 9, 10, -38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-01 20:48:53.446701: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-01 20:48:53.446850: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-01 20:48:53.447227: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mpf-lptp-044): /proc/driver/nvidia/version does not exist\n",
      "2022-09-01 20:48:53.451130: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units = 1, activation = tf.keras.activations.relu, input_shape = (3,)))\n",
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(0.001), loss = tf.keras.losses.mean_squared_error, metrics = [tf.keras.metrics.mean_squared_error])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.0988724]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data, testing_data, epochs = 1, verbose = 'True')\n",
    "print(\"Traning completed.\")\n",
    "model.predict(np.array([[1, 2, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"/home/pradeep/Downloads/2.jpg\")\n",
    "\n",
    "lower = np.array([35, 25, 25], dtype=\"uint8\")\n",
    "higher = np.array([100, 255, 255], dtype=\"uint8\")\n",
    "\n",
    "# print(\"img_shape \", img.shape)\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(hsv, lower, higher)\n",
    "# slice the green\n",
    "imask = mask > 0\n",
    "green = np.zeros_like(img, np.uint8)\n",
    "green[imask] = img[imask]\n",
    "\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "dilate = cv2.dilate(green, kernel)\n",
    "\n",
    "aa, bb, cc = cv2.split(dilate)\n",
    "bmask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "\n",
    "(T, threshInv) = cv2.threshold(bb, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "selected_cnts = []\n",
    "contours0, hierarchy = cv2.findContours(\n",
    "    threshInv, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for c in contours0:\n",
    "    area = cv2.contourArea(c)\n",
    "    if (area >= 100 and area <= 1500):\n",
    "\n",
    "        selected_cnts.append(c)\n",
    "\n",
    "cv2.drawContours(bmask, selected_cnts, -1,255, -1)\n",
    "# cv2.drawContours(img,selected_cnts, -1,(0, 25,255), -1)\n",
    "\n",
    "masked = cv2.bitwise_and(img, img, mask=bmask)\n",
    "\n",
    "resize=cv2.resize(masked,(1600,800))\n",
    "cv2.imshow(\"output\",resize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#cv2.imwrite(\"/home/pradeep/Downloads/phone_inp/masked.jpg\", masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img1=cv2.imread(\"/home/pradeep/Downloads/phone_inp/IMG_20220907_152656_ed.jpg\")\n",
    "img2=cv2.imread(\"/home/pradeep/Downloads/phone_inp/masked.jpg\")\n",
    "\n",
    "img3=cv2.imread(\"/home/pradeep/Downloads/phone_inp/IMG_20220907_152656.jpg\")#input\n",
    "img4=cv2.imread(\"/home/pradeep/Downloads/phone_inp/overlay_uv_and_white.jpg\")#overlay\n",
    "\n",
    "\n",
    "weighted=cv2.addWeighted(img1,0.7,img2,0.3,0)\n",
    "\n",
    "resize=cv2.resize(weighted,(1600,800))\n",
    "\n",
    "cv2.imwrite(\"/home/pradeep/Downloads/phone_inp/overlay_uv_and_white.jpg\",weighted)\n",
    "cv2.imshow(\"output\",resize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row=cv2.hconcat([img3,img1])\n",
    "second_row=cv2.hconcat([img2,img4])\n",
    "\n",
    "final_output=cv2.vconcat([first_row,second_row])\n",
    "\n",
    "resize1=cv2.resize(final_output,(1600,800))\n",
    "\n",
    "cv2.imwrite(\"/home/pradeep/Downloads/phone_inp/outpu1.jpg\",final_output)\n",
    "cv2.imshow(\"output\",resize1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m subtract\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mbitwise_xor(\u001b[43mimg1\u001b[49m,img4)\n\u001b[1;32m      2\u001b[0m resize2\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mresize(subtract,(\u001b[38;5;241m1600\u001b[39m,\u001b[38;5;241m800\u001b[39m))\n\u001b[1;32m      3\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,resize2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img1' is not defined"
     ]
    }
   ],
   "source": [
    "subtract=cv2.bitwise_xor(img1,img4)\n",
    "resize2=cv2.resize(subtract,(1600,800))\n",
    "cv2.imshow(\"output\",resize2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) /tmp/pip-req-build-afu9cjzs/opencv/modules/imgcodecs/src/loadsave.cpp:732: error: (-2:Unspecified error) could not find a writer for the specified extension in function 'imwrite_'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m---> 13\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/pradeep/Downloads/phone_inp_2828/phone_inp/output_ed_lib_with_defect_red\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.3) /tmp/pip-req-build-afu9cjzs/opencv/modules/imgcodecs/src/loadsave.cpp:732: error: (-2:Unspecified error) could not find a writer for the specified extension in function 'imwrite_'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "img1=cv2.imread(\"/home/pradeep/Downloads/gradImg.jpg\")\n",
    "img2=cv2.imread(\"/home/pradeep/Downloads/phone_inp_2828/phone_inp/omitted_frameIMG_20220907_162828.jpg\",0)\n",
    "blank = np.zeros(img2.shape, dtype= np.uint8)\n",
    "img2 = cv2.merge([blank, blank, img2])\n",
    "weighted=cv2.addWeighted(img1,0.5,img2,0.5,0)\n",
    "\n",
    "first_row=cv2.hconcat([img1,weighted])\n",
    "resize1=cv2.resize(first_row,(1600,800))\n",
    "cv2.imshow(\"output\",resize1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite(\"/home/pradeep/Downloads/phone_inp_2828/phone_inp/output_ed_lib_with_defect_red\",img2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img3=cv2.imread(\"/home/pradeep/Downloads/phone_inp_2828/phone_inp/IMG_20220907_162828_ed.jpg\")\n",
    "img4=cv2.imread(\"/home/pradeep/Downloads/phone_inp_2828/phone_inp/output_red.jpg\")\n",
    "# blank = np.zeros(img4.shape, dtype= np.uint8)\n",
    "# img4 = cv2.merge([blank, blank, img4])\n",
    "weighted=cv2.addWeighted(img3,0.5,img4,0.5,0)\n",
    "\n",
    "first_row1=cv2.hconcat([img3,weighted])\n",
    "resize2=cv2.resize(img4,(1600,800))\n",
    "cv2.imshow(\"output\",resize2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite(\"/home/pradeep/Downloads/phone_inp_2828/phone_inp/output_red_contour_overlay.jpg\",weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1=cv2.imread(\"/home/pradeep/Downloads/phone_inp_2828/phone_inp/IMG_20220907_162828.jpg\")\n",
    "img2=cv2.imread(\"/home/pradeep/Downloads/phone_inp_2828/phone_inp/IMG_20220907_162828_ed.jpg\")\n",
    "img3=cv2.imread(\"/home/pradeep/Downloads/phone_inp_2828/phone_inp/lowlight.jpg\")\n",
    "img4=cv2.imread(\"/home/pradeep/Downloads/phone_inp_2828/phone_inp/output_red.jpg\")\n",
    "img5=cv2.imread(\"/home/pradeep/Downloads/phone_inp_2828/phone_inp/output_red_contour_overlay.jpg\")\n",
    "img6=cv2.imread(\"/home/pradeep/Downloads/phone_inp_2828/phone_inp/output_red_defect_overlay.jpg\")\n",
    "\n",
    "\n",
    "\n",
    "first_row=cv2.hconcat([img1,img2,img3])\n",
    "second_row=cv2.hconcat([img4,img5,img6])\n",
    "\n",
    "final_output=cv2.vconcat([first_row,second_row])\n",
    "\n",
    "resize1=cv2.resize(final_output,(1600,800))\n",
    "\n",
    "cv2.imwrite(\"/home/pradeep/Downloads/phone_inp_2828/phone_inp/Meeting/outpu1.jpg\",final_output)\n",
    "cv2.imshow(\"output\",resize1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(frame, scale=0.5):\n",
    "    width, height = int(scale * frame.shape[1]), int(scale * frame.shape[0])\n",
    "    return cv2.resize(frame, (width,height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def imshow(label, img, scale=0.5):\n",
    "    cv2.imshow(label, resize(img, scale))\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img1=cv2.imread(\"/home/pradeep/Downloads/phone_inp_2828/phone_inp/IMG_20220907_162828.jpg\", 0)\n",
    "blank = np.zeros(img1.shape[:2], dtype=np.uint8)\n",
    "\n",
    "colored = cv2.merge([ img1, blank, blank])\n",
    "imshow(\"img1\", colored, 0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) /tmp/pip-req-build-afu9cjzs/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m higher \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(\"img_shape \", img.shape)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m hsv \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2HSV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39minRange(hsv, lower, higher)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# slice the green\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.3) /tmp/pip-req-build-afu9cjzs/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"/home/pradeep/Downloads/phone_inp_2828/phone_inp/Material#3_uv_output.jpg\")\n",
    "\n",
    "lower = np.array([35, 25, 25], dtype=\"uint8\")\n",
    "higher = np.array([100, 255, 255], dtype=\"uint8\")\n",
    "\n",
    "# print(\"img_shape \", img.shape)\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(hsv, lower, higher)\n",
    "# slice the green\n",
    "imask = mask > 0\n",
    "green = np.zeros_like(img, np.uint8)\n",
    "green[imask] = img[imask]\n",
    "\n",
    "kernel = np.ones((7, 3), np.uint8)\n",
    "dilate = cv2.dilate(green, kernel,iterations=9)\n",
    "errode=cv2.erode(dilate,kernel,iterations=5)\n",
    "\n",
    "aa, bb, cc = cv2.split(errode)\n",
    "bmask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "\n",
    "(T, threshInv) = cv2.threshold(bb, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "selected_cnts = []\n",
    "contours0, hierarchy = cv2.findContours(\n",
    "    threshInv, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for c in contours0:\n",
    "    area = cv2.contourArea(c)\n",
    "    \n",
    "    if (area >= 1900 and area <= 5000):\n",
    "\n",
    "        selected_cnts.append(c)\n",
    "\n",
    "cv2.drawContours(bmask,selected_cnts, -1,255, -1)\n",
    "# cv2.drawContours(img,selected_cnts, -1,(0, 25,255), -1)\n",
    "\n",
    "masked = cv2.bitwise_and(img, img, mask=bmask)\n",
    "\n",
    "resize=cv2.resize(masked,(1600,800))\n",
    "cv2.imshow(\"output\",resize)\n",
    "\n",
    "# resize1=cv2.resize(img,(1600,800))\n",
    "# cv2.imshow(\"output1\",resize1)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imwrite(\"/home/pradeep/Desktop/Bosch_output/Material#3_uv_output_defect.jpg\", masked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original=cv2.imread(\"/home/pradeep/Desktop/Bosch_output/Material#3white.jpg\")\n",
    "overlay=cv2.addWeighted(original,0.6,masked,0.4,0)\n",
    "resize=cv2.resize(overlay,(1600,800))\n",
    "cv2.imshow(\"output\",resize)\n",
    "\n",
    "# resize1=cv2.resize(img,(1600,800))\n",
    "# cv2.imshow(\"output1\",resize1)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite(\"/home/pradeep/Desktop/Bosch_output/Material#3_output.jpg\", overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number is equal to 001\n",
      "number is equal to 002\n",
      "number is equal to 003\n",
      "number is equal to 004\n",
      "number is equal to 005\n"
     ]
    }
   ],
   "source": [
    "number=1\n",
    "for i in range(5):\n",
    "\n",
    "    print(f'number is equal to {number:03d}')\n",
    "    number=number+1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
